\chapter*{\centerline{ABSTRACT}}
\addcontentsline{toc}{chapter}{ABSTRACT}
\thispagestyle{plain}
\vspace{-0.5cm}
Mobile applications frequently request permissions that exceed functional requirements, exposing users to significant privacy risks. Existing security frameworks primarily emphasize malware detection and provide limited mechanisms to evaluate privacy sensitivity or contextual justification of permissions. This research introduces a \textbf{Multi-Modal Hybrid Neural Network (MM-HNN)} framework for supervised privacy risk classification of Android applications using app metadata, manifest-declared permissions, genre information, and application descriptions.
The proposed framework combines two complementary neural architectures. A \textbf{Variational Autoencoder (VAE)} learns compact latent representations of permission and metadata vectors, enhanced with a \textbf{classification layer} trained on manually annotated privacy risk labels. In parallel, \textbf{DistilBERT} extracts contextual semantic features that capture the alignment between requested permissions and declared app functionality. The system fuses latent structural features and semantic embeddings to build a multimodal classifier capable of identifying privacy-invasive behavior.
Trained on a labeled dataset of Nepali-region Android applications, the MM-HNN model is evaluated using standard classification metrics, including accuracy, F1-score, AUC, and confusion matrices. Results demonstrate that the multimodal fusion approach outperforms single-modality baselines by effectively integrating structural anomalies with contextual relevance signals. The framework operates within Androidâ€™s permission model and Google Play Store guidelines, providing a practical foundation for automated, data-driven mobile privacy risk assessment tools.
\par
\textbf{Keywords:} \textit{Multi-Modal Neural Networks, Variational Autoencoders, Privacy Risk Classification, Permission Analysis, Semantic Alignment, Android Privacy}