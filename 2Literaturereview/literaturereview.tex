\chapter{LITERATURE REVIEW}

The rapid expansion of mobile applications has dramatically reshaped the digital ecosystem, driving unprecedented user engagement while simultaneously intensifying security and privacy concerns. Early defensive mechanisms—such as signature-based antivirus tools, heuristic scanners, and basic static analysis—have proven increasingly inadequate against modern threats, including polymorphic malware, advanced obfuscation strategies, and subtle forms of permission misuse. As a result, research directions have progressively shifted toward machine learning (ML), deep learning (DL), and, more recently, Large Language Models (LLMs) for analyzing application behavior, metadata, permissions, and user-facing descriptions. This chapter surveys these developments across four major research directions: LLM-based security analysis, multimodal deep learning, graph-based techniques, and conventional ML approaches. It concludes by identifying open research gaps that motivate the proposed MM-HNN framework.

\section{Large Language Models (LLMs) in Mobile Security}

Large Language Models (LLMs) have attracted considerable interest due to their capability to process and generate both structured program code and natural language. Chen et al.~\cite{chen2021evaluating} demonstrated that Codex, an LLM trained on large-scale code repositories, can infer program structure and logic with high accuracy. Khare et al.~\cite{khare2023understanding} conducted a comprehensive evaluation of 16 different LLMs across multiple vulnerability datasets and reported noticeable performance variations across vulnerability categories. Liu et al.~\cite{liu2024vuldetectbench} introduced VulDetectBench, a standardized benchmark for assessing LLM performance in vulnerability detection. Their study showed that while LLMs handle coarse-grained vulnerability reasoning reasonably well, fine-grained semantic vulnerabilities remain difficult to detect reliably.

Although these studies highlight the promise of LLMs for security analysis, their application to mobile privacy risk—particularly the alignment between requested permissions and application functionality—has received limited attention. Moreover, Pearce et al.~\cite{pearce2021asleep} reported that code generated by LLMs often contains security flaws, underscoring the risks of relying solely on automated semantic reasoning for secure software development.

\subsection{LLM Deployment Constraints in Mobile Contexts}

Despite their analytical power, LLMs face significant challenges when considered for direct deployment in mobile environments. Prior work has emphasized their dependence on substantial memory resources, high computational capacity, and stable network connectivity~\cite{kouliaridis2024effectiveness}. Even compact LLM variants introduce non-negligible inference latency and energy consumption, making real-time or on-device deployment impractical for most user-facing applications. In addition, cloud-based processing of mobile data introduces further privacy concerns, particularly when sensitive application information is transmitted for remote inference.

This thesis does not attempt on-device LLM deployment or inference optimization. Instead, these constraints are discussed to justify the design choice of using DistilBERT as a lightweight yet semantically effective server-side language model.

\subsection{Contextual Understanding and Explainability}

Kouliaridis et al.~\cite{kouliaridis2024effectiveness} evaluated LLMs such as GPT-4 for Android vulnerability detection using extended contextual information and reported an accuracy of 89.3\%. However, their study also highlighted substantial latency and privacy limitations. Zhong et al.~\cite{zhong2024advanced} proposed a hybrid detection framework that integrates generative models with gradient-based explainable AI (XAI), achieving 93.1\% accuracy. Despite the strong detection performance, the reliance on computationally intensive gradient attribution techniques restricts the applicability of such systems in mobile-oriented or real-time analysis tools.

\subsection{Hybrid Static–Dynamic LLM Methods}

Mathews et al.~\cite{mathews2024llbezpeky} introduced \textit{LLbezpeky}, a hybrid framework that combines static analysis with LLM-driven dynamic test case generation. Their system achieved a detection rate of 91.67\% on the Ghera benchmark. However, obfuscation significantly increased the false-positive rate, indicating limitations in semantic robustness. Yang et al.~\cite{yang2024security} investigated vulnerabilities in multimodal AI agents processing text, images, and audio inputs, achieving 87\% detection accuracy. While these studies address complex multimodal threat surfaces, their focus differs substantially from permission–functionality alignment in privacy-oriented mobile analysis.

In summary, while LLMs offer strong semantic reasoning capabilities, their high computational demands, reliance on cloud infrastructure, and lack of privacy-focused mobile datasets limit their direct applicability. These challenges motivate the exploration of hybrid, multi-modal systems that balance semantic depth with practical efficiency.

\section{Multimodal and Deep Learning Approaches}

Deep learning has enabled more advanced integration of heterogeneous features extracted from Android applications. Park et al.~\cite{park2024multimodal} proposed \textit{MultiVulnDet}, which combines CNN-based binary visualization with Transformer-based code sequence modeling, achieving 89.5\% accuracy. However, the model’s dependence on large annotated datasets and high computational costs constrains its scalability.

Chen et al.~\cite{chen2023deepvuln} developed \textit{DeepVuln}, a Bi-LSTM-based architecture enhanced with attention mechanisms, reporting an accuracy of 87.2\%. While effective for learning sequential patterns, Bi-LSTM models struggle with long-range dependencies and generalization to unseen vulnerabilities. Wang et al.~\cite{wang2022vulnhunter} presented \textit{VulnHunter}, which emphasizes third-party library vulnerability detection and achieved 86.4\% accuracy. Nevertheless, its design primarily targets backend systems rather than user-facing privacy assessment.

Overall, most existing multimodal deep learning systems focus on malware or vulnerability detection rather than on evaluating excessive permission requests or identifying semantic inconsistencies between application descriptions and declared permissions. This limitation is directly addressed in the design of the MM-HNN framework.

\section{Graph-Based and Conventional Machine Learning Techniques}

Before the widespread adoption of deep learning and LLM-based approaches, Android security research was dominated by graph-based and traditional machine learning techniques.

\subsection{Graph Neural Networks (GNNs)}

Zhang and Roberts~\cite{zhang2023secureflow} proposed \textit{SecureFlow}, which models Android applications using call graphs and data-flow graphs. By applying Graph Neural Networks (GNNs), their approach achieved 88.7\% accuracy in vulnerability detection. However, constructing and processing large-scale graph representations is computationally demanding, limiting the feasibility of such approaches for lightweight or privacy-oriented deployment.

\subsection{Ensemble and Traditional ML}

Conventional ML methods offer lower computational overhead but lack deep semantic understanding. Kumar et al.~\cite{kumar2023mlvuln} developed a hybrid ensemble model combining neural networks and decision trees, achieving 89\% detection accuracy. Earlier work~\cite{ml2022vulnerability} optimized Random Forest classifiers using manually engineered features. Despite their efficiency, these models treat permissions as flat feature vectors and do not incorporate contextual reasoning.

For instance, while a traditional ML model may flag a calculator application requesting location access as suspicious, it cannot determine whether such a request is justified based on the app’s stated functionality. This fundamental semantic limitation motivates the need for multi-modal systems that combine structured features with natural language understanding.

\section{Critical Analysis and Research Gaps}

A critical examination of the literature reveals several persistent gaps:

\begin{enumerate}
    \item \textbf{Absence of Semantic Permission–Functionality Validation:} Most existing tools analyze permissions or application behavior independently, without verifying whether requested permissions are justified by the declared purpose of the app.

    \item \textbf{Efficiency–Accuracy Trade-Off:} High-accuracy deep learning and LLM-based systems are computationally expensive, whereas lightweight ML models remain limited in contextual reasoning.

    \item \textbf{Limited Interpretability for End Users:} Many deep learning systems operate as black boxes, offering probability scores without providing intuitive explanations such as “location access is inconsistent with a wallpaper application.”

    \item \textbf{Restrictions on Runtime Monitoring:} Modern Android security restrictions limit dynamic monitoring for non-rooted devices, making static artifacts such as permissions, metadata, and descriptions increasingly important for privacy analysis.
\end{enumerate}

\section{Positioning the MM-HNN Framework}

The proposed MM-HNN framework is designed to directly address the above limitations through a hybrid multi-modal architecture that integrates structured permission analysis with semantic understanding.

\begin{itemize}
    \item \textbf{Variational Autoencoder (VAE) for Structured Features:} The VAE models permission distributions and metadata relationships, enabling efficient detection of anomalous permission–category patterns with minimal computational overhead.

    \item \textbf{DistilBERT for Semantic Understanding:} DistilBERT captures contextual meaning from app descriptions and privacy policies, allowing the system to evaluate whether requested permissions align with declared application functionality.

    \item \textbf{Supervised Risk Classification:} By fusing structured and semantic representations, MM-HNN assigns applications to privacy risk categories that are meaningful for both users and regulatory compliance.
\end{itemize}

Through this balanced fusion of efficiency and semantic depth, the MM-HNN framework overcomes key limitations of prior methods and provides a scalable, interpretable, and practical foundation for automated mobile privacy risk assessment.
