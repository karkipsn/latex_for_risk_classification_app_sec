\chapter{INTRODUCTION}

\section{Background}
Mobile applications have become an essential part of daily life, providing range of services from messaging and social networking to banking, health casre, and entertainment. The widespread growwth of smartphones and app ecosystems has accelerated digital innovation, but it has also introduced significant privacy and security challenges. Android’s permission model is the primary mechanism by which applications request access to sensitive device resources (e.g., location, contacts, camera, microphone) and user data; these permissions are declared in an app’s manifest and may be granted at install time or at runtime depending on the permission type and Android version \cite{androidPermissionsDevs, androidAOSPpermissions, androidDeclarePermissions}. Prior work has shown that users frequently grant permissions without fully understanding their implications, and developers vary widely in how transparently they justify permission usage \cite{felt2011android, chen2023deepvuln, peng2012using}.

Previous research indicates that users often approve permissions without fully understanding their implications, while developers differ widely in how clearly they justify permission usage \cite{felt2011android, chen2023deepvuln, peng2012using}. Traditional mobile security research has primarily focused on identifying malicious behavior using static and dynamic analysis, as well as signature- and behavior-based detection techniques \cite{enck2014, li2017, mitchell2020guardml}. Although these methods are effective for detecting malware and runtime threats, they do not adequately address privacy risks arising from legitimate applications that request excessive or poorly justified permissions. 

Privacy risk is inherently multifaceted. It depends not only on the permissions requested, but also on the application’s stated functionality, developer behavior, and how metadata such as category, ratings, and update history correlate with permission usage \cite{zhu2019, ferreira2020}. Recent advances in machine learning and natural language processing enable the joint analysis of structured metadata and unstructured textual content, such as app descriptions and privacy policy excerpts. This capability makes it possible to detect misalignments between requested permissions and declared functionality \cite{park2024multimodal, Zilliz2024}.

Variational Autoencoders (VAEs) and other latent-variable models have shown strong performance in anomaly detection and representation learning across heterogeneous data domains \cite{vandeKleut2021, an_variational_2015}. At the same time, transformer-based language models, including DistilBERT, provide powerful semantic representations for short textual documents and application descriptions \cite{Zilliz2024, sanh_distilbert_2020}. A multimodal approach that integrates latent structural representations of permissions and metadata with semantic text embeddings offers the potential for more reliable, interpretable, and scalable privacy risk assessment than single-modality systems.


\section{Motivation}

Despite the clear platform specific safeguards and developer guidelines, many applications continue to request permissions that appear disproportionate to their stated features or to user expectations. Large-scale studies and industry reports consistently highlight ongoing privacy risks caused by excessive data collection, third-party analytics, and non-transparent developer practices \cite{ZimperiumRiskAssessment2024, kaseb2022}. Given the enormous scale of modern app marketplaces, manual review of millions of applications is impractical for regulators and platform operators. Moreover, most existing automated analysis tools are designed primarily for malware detection rather than for nuanced privacy evaluation \cite{enck2014, zhu2019}.

There is therefore a strong practical and academic need for automated systems that can reason about the contextual justification of requested permissions—specifically, whether permissions align with an application’s described functionality. Such systems should also be capable of identifying structural anomalies in permission and metadata vectors, while producing outputs that are interpretable for diverse stakeholders, including users, developers, enterprises, and regulators. By combining structural representation learning with semantic analysis, it becomes possible to improve the precision and trustworthiness of privacy risk classification in real-world mobile ecosystems \cite{park2024multimodal, Zilliz2024}.

Additionally, regional app ecosystems, including applications developed for Nepali users, may exhibit distinct permission usage patterns and metadata characteristics that are underrepresented in global datasets. Constructing and validating a labeled dataset that reflects such local app behavior enhances the relevance, robustness, and fairness of automated privacy assessment models.

\section{Problem Statement}

Many Android applications request permissions that exceed their operational needs or lack clear justification in their descriptions and metadata. This behavior creates privacy risks that are not effectively captured by malware-focused detection systems or by simple heuristics based on permission counts alone. Current automated approaches generally fall short in several respects:

\begin{itemize}
\item Dependence on single-modality analysis, either purely structural or purely textual, which fails to capture cross-modal inconsistencies \cite{zhu2019, park2024multimodal}.
\item Limited availability of labeled datasets that explicitly encode privacy risk levels for supervised evaluation, particularly for regionally focused applications \cite{androzoo, krifyCategory2024}.
\item Insufficient interpretability for stakeholders who must assess whether permission requests comply with legal and regulatory frameworks such as GDPR and CCPA \cite{GDPR2024, CCPA2024}.
\end{itemize}

This research formulates the task as a supervised privacy risk classification problem: given an Android application’s manifest-declared permissions, metadata, and textual description, the objective is to predict a privacy risk label reflecting the likelihood of unjustified or excessive data access. The core challenge lies in designing a multimodal model that can capture latent structural anomalies in permission vectors, understand semantic alignment between descriptions and permissions, and effectively fuse these signals into a robust and interpretable classifier suitable for real-world deployment.


\section{Objectives}
The objectives of this thesis are:

\begin{enumerate}
\item To construct and validate a manually labeled dataset of Android applications with regional representation.
% and to evaluate the MM-HNN using standard supervised metrics (accuracy, precision, recall, F1-score, AUC), baseline comparisons, and ablation studies.

\item To develop a supervised multimodal hybrid neural network (MM-HNN) to predict privacy risk levels.
% that integrates a VAE-based latent representation of permissions and metadata with a DistilBERT-based semantic encoder for app descriptions, and that includes a classification head 


\end{enumerate}

\section{Scope}
The scope of this research is defined as follows:

\begin{itemize}
\item \textbf{Data sources and modalities:} The study relies exclusively on static, publicly available app metadata, including manifest-declared permissions, app descriptions, categories, developer information, and content ratings \cite{androidPermissionsDevs, googlePlayUserData2024}.

\item \textbf{Modeling approach:} The thesis designs and evaluates a supervised multimodal framework that combines a VAE for structural feature learning with a DistilBERT encoder for semantic feature extraction. Multiple fusion strategies and classification head designs are explored.

\item \textbf{Evaluation:} Model performance is assessed using labeled data and standard supervised classification metrics, along with ablation studies to measure the contribution of each modality.
% The research includes qualitative analysis (case studies, latent-space visualizations) to aid interpretability.
\item \textbf{Excluded topics:} Dynamic runtime analysis, network traffic inspection, taint tracking, and active privacy policy scraping beyond publicly available descriptions are excluded. Adversarial evasion techniques are also considered outside the scope of the core contribution.
\end{itemize}
\end{itemize}


\section{Potential Applications}
The MM-HNN framework has broad applicability across the mobile ecosystem:

\begin{itemize}
\item \textbf{End users:} Providing clearer, data-driven privacy risk indicators at install time to support informed consent \cite{privacyDashboard2021}.
\item \textbf{App stores and marketplace operators:} Automating preliminary privacy vetting by flagging apps with inconsistent permission practices \cite{googlePlayDeveloperPolicyCenter, googlePlayUserData2024}.
\item \textbf{Developers:} Offering pre-submission privacy checks that encourage permission minimization and improved documentation \cite{googlePrepareAppReview, iubendaPrivacyPolicyAndroid}.
\item \textbf{Enterprises and IT administrators:} Screening third-party applications for deployment on corporate devices to reduce compliance risks.
\item \textbf{Regulators and auditors:} Supporting large-scale compliance investigations under frameworks such as GDPR and CCPA \cite{GDPR2024, CCPA2024}.
\item \textbf{Security researchers:} Enabling systematic and longitudinal studies of privacy trends across app categories and regions \cite{park2024multimodal, ZimperiumRiskAssessment2024}.
\end{itemize}


\section{Originality of the Thesis}

This thesis introduces a \textbf{supervised, multi-modal, and data-driven framework} for assessing privacy risks in Android applications. The originality of this work lies in several key aspects:

\begin{enumerate}
    \item \textbf{Manually Labeled Privacy Risk Dataset:} A primary contribution is the creation of a validated dataset of Android applications annotated with privacy risk labels. This dataset enables supervised training and provides a benchmark for future research in mobile privacy assessment.
    
    \item \textbf{Supervised Multi-Modal Learning:} The proposed MM-HNN framework integrates \textbf{Variational Autoencoders (VAE)} to extract structured features from app metadata and permissions, along with \textbf{DistilBERT} embeddings for semantic analysis of textual descriptions and privacy policies. A classification layer combines these modalities to predict discrete privacy risk levels.
    
    \item \textbf{Risk Classification and Confidence Scores:} Unlike purely anomaly-based methods, the framework produces both privacy risk classes and associated confidence scores, offering actionable insights for users, developers, and regulators.
    
    \item \textbf{Scalability and Practical Applicability:} By operating on static app information, the framework can efficiently evaluate large-scale datasets while maintaining the reliability of predictions through supervised learning on manually labeled data.
\end{enumerate}


\section{Organization of the Report}
This thesis is organized as follows:

\begin{itemize}
\item \textbf{Chapter 1: Introduction} – Background, motivation, problem statement, objectives, scope, applications, and originality.
\item \textbf{Chapter 2: Literature Review} – Review of existing mobile security and privacy research and identification of research gaps.
\item \textbf{Chapter 3: Methodology} – Detailed description of data collection, model architecture, training procedures, and evaluation strategy.
\item \textbf{Chapter 4: Results} – Presentation of experimental results and performance evaluation.
\item \textbf{Chapter 5: Discussion and Analysis} – Interpretation of results and comparison with related work.
\item \textbf{Chapter 6: Conclusion and Future Work} – Summary of findings and directions for future research.
\end{itemize}
